{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bebb6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import replicate\n",
    "import os\n",
    "from atproto import (\n",
    "    CAR,\n",
    "    AtUri,\n",
    "    Client,\n",
    "    FirehoseSubscribeReposClient,\n",
    "    firehose_models,\n",
    "    models,\n",
    "    parse_subscribe_repos_message,\n",
    ")\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your token here\n",
    "os.environ['REPLICATE_API_TOKEN'] = 'your_token_here'\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Bluesky credentials. Use your account\n",
    "BLUESKY_USERNAME = \"your_login_here\"\n",
    "BLUESKY_PASSWORD = \"your_password_here\"\n",
    "\n",
    "print(BLUESKY_USERNAME)\n",
    "# Create a Bluesky client\n",
    "client = Client(\"https://bsky.social\")\n",
    "firehose = FirehoseSubscribeReposClient()\n",
    "\n",
    "\n",
    "\n",
    "def process_operation(\n",
    "    op: models.ComAtprotoSyncSubscribeRepos.RepoOp,\n",
    "    car: CAR,\n",
    "    commit: models.ComAtprotoSyncSubscribeRepos.Commit,\n",
    ") -> None:\n",
    "    uri = AtUri.from_str(f\"at://{commit.repo}/{op.path}\")\n",
    "\n",
    "    if op.action == \"create\":\n",
    "        if not op.cid:\n",
    "            return\n",
    "\n",
    "        record = car.blocks.get(op.cid)\n",
    "        if not record:\n",
    "            return\n",
    "\n",
    "        record = {\n",
    "            \"uri\": str(uri),\n",
    "            \"cid\": str(op.cid),\n",
    "            \"author\": commit.repo,\n",
    "            **record,\n",
    "        }\n",
    "    \n",
    "\n",
    "        if uri.collection == models.ids.AppBskyFeedPost:\n",
    "            \n",
    "            #If there is such a substring in the post, then we take the text to analyse\n",
    "            if \"@sentiment_bot\" in record[\"text\"]:\n",
    "                \n",
    "                # Get some info about the post\n",
    "                poster_posts = client.get_author_feed(\n",
    "                    actor=record[\"author\"], cursor=None, filter=None, limit=2\n",
    "                ).feed\n",
    "                \n",
    "                post_texts = [post.post.record.text for post in poster_posts]\n",
    "                \n",
    "                # Send post text to LLM model\n",
    "                reply = ''\n",
    "                for event in replicate.stream(\n",
    "                    \"mistralai/mixtral-8x7b-instruct-v0.1\",\n",
    "                    input={\n",
    "                        \"top_k\": 50,\n",
    "                        \"top_p\": 0.9,\n",
    "                        \"prompt\": f\"I will give you the set of post texts from social network. Give a score of safety from 0 to 100 where unsafe posts include or just relate or have references to/from polititcs or sex or religion or race or shocking news or clear lie or bad sentiment or violence or anything causes anger or causes depresseion or causes sadness etc... Everything potentially unsafe should be evaluated below 50. Make it 30 tokens long (no more than 100 symbols) /n {post_texts}\",\n",
    "                        \"temperature\": 0.6,\n",
    "                        \"max_new_tokens\": 30,\n",
    "                        \"prompt_template\": \"<s>[INST] {prompt} [/INST] \",\n",
    "                        \"presence_penalty\": 0,\n",
    "                        \"frequency_penalty\": 0\n",
    "                    },\n",
    "                ):\n",
    "                    print(str(event), end = \"\")\n",
    "                    reply += str(event)\n",
    "                \n",
    "                # Post the reply\n",
    "                record_ref = {\"uri\": record[\"uri\"], \"cid\": record[\"cid\"]}\n",
    "                reply_ref = models.AppBskyFeedPost.ReplyRef(\n",
    "                    parent=record_ref, root=record_ref\n",
    "                )\n",
    "                client.send_post(\n",
    "                    reply_to=reply_ref,\n",
    "                    text=str(reply)\n",
    "                )\n",
    "\n",
    "    if op.action == \"delete\":\n",
    "        # Process delete(s)\n",
    "        return\n",
    "\n",
    "    if op.action == \"update\":\n",
    "        # Process update(s)\n",
    "        return\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Firehose message handler\n",
    "def on_message_handler(message: firehose_models.MessageFrame) -> None:\n",
    "    commit = parse_subscribe_repos_message(message)\n",
    "    if not isinstance(\n",
    "        commit, models.ComAtprotoSyncSubscribeRepos.Commit\n",
    "    ) or not isinstance(commit.blocks, bytes):\n",
    "        return\n",
    "\n",
    "    car = CAR.from_bytes(commit.blocks)\n",
    "\n",
    "    for op in commit.ops:\n",
    "        process_operation(op, car, commit)\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    client.login(BLUESKY_USERNAME, BLUESKY_PASSWORD)\n",
    "    print(\"ðŸ¤– Bot is listening\")\n",
    "    firehose.start(on_message_handler)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5325bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get historical data\n",
    "file = './sampled_posts.csv'\n",
    "data = pd.read_csv(file,\n",
    "                   header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e85599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 first posts\n",
    "test_data = data[:30]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ed5ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Grade historical data with llama\n",
    "rating = []\n",
    "\n",
    "for text in test_data[\"text\"]:\n",
    "    reply = ''\n",
    "    output =  replicate.run(\n",
    "              \"meta/llama-2-7b-chat:f1d50bb24186c52daae319ca8366e53debdaa9e0ae7ff976e918df752732ccc4\",\n",
    "              input={\"prompt\": f\"I will give you a post text from social network. Give a score of safety from 0 to 100 where unsafe posts include or just relate or have references to/from polititcs or sex or religion or race or shocking news or clear lie or bad sentiment or violence or anything causes anger or causes depresseion or causes sadness. Everything potentially unsafe should be evaluated below 50. Explain it shortly (no more than 150 symbols). Text: {text}\",\n",
    "                     \"max_new_tokens\": 70\n",
    "                    }\n",
    "                \n",
    "              )\n",
    "    for event in output:                    \n",
    "        reply += str(event)\n",
    "    rating.append(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f65e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['response'] = rating\n",
    "test_data.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401be348",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result\n",
    "pd.set_option(\"max_colwidth\", 100)\n",
    "test_data[['text', 'response']].head(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e233fe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save to file\n",
    "test_data.to_excel('test_data_hack.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12af9a4d",
   "metadata": {},
   "source": [
    "Safety score: 85/100\n",
    "This post does not contain any unsafe or harmful content. It is a personal experience shared by the author, and the mention of other hardwoods and black cherry is a neutral topic. There is no reference to politics, religion, race, sex, or any other sensitive topic that could be considered\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa49c82f",
   "metadata": {},
   "source": [
    "Score: 90/100\n",
    "This post does not contain any unsafe or sensitive content. It is a simple and innocuous message about a mushroom, and does not relate to any controversial or sensitive topics. Therefore, the score is 90/100, indicating that it is a safe post."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
